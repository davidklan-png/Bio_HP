"""Interactive prompt test harness.

Best-practice note:
- Keep templates versioned and testable.
- Validate output shape before integrating into production workflows.
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path


SUPPORTED_MODELS = {"codex-5.3", "opus-4.6", "glm"}


def load_template(path: Path) -> str:
    if not path.exists():
        raise FileNotFoundError(f"Template not found: {path}")
    return path.read_text(encoding="utf-8")


def render_template(template: str, user_input: str) -> str:
    return template.replace("{{user_input}}", user_input)


def fake_model_call(model: str, prompt: str) -> dict:
    # Replace this stub with real SDK calls and response parsing.
    _ = prompt
    return {
        "model": model,
        "summary": "Example summary generated by stubbed model call.",
        "assumptions": ["Input data is representative of production patterns."],
        "recommended_actions": [
            "Add prompt-level schema validation.",
            "Run variant tests across model providers.",
            "Track quality and latency before deployment.",
        ],
        "risks": ["Overfitting prompts to narrow benchmark prompts."],
    }


def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--template", required=True, type=Path)
    parser.add_argument("--input", required=True)
    parser.add_argument("--model", default="codex-5.3")
    args = parser.parse_args()

    if args.model not in SUPPORTED_MODELS:
        raise ValueError(f"Unsupported model: {args.model}. Choose from {sorted(SUPPORTED_MODELS)}")

    template = load_template(args.template)
    rendered = render_template(template, args.input)
    response = fake_model_call(args.model, rendered)

    print("\n--- Rendered Prompt ---")
    print(rendered)
    print("\n--- Model Response (Stub) ---")
    print(json.dumps(response, indent=2))


if __name__ == "__main__":
    main()
