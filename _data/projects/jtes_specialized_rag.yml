id: jtes_specialized_rag
detail_page: /projects/japanese-tax-expert-system-jtes-specialized-rag-for-professionals/
name: Japanese Tax Expert System (JTES) â€“ Specialized RAG for Professionals
one_line_value: Domain-specialized RAG system targeting high-precision, citation-backed tax guidance for professionals.
icon: rag
tags:
  - Specialized RAG
  - Citation Fidelity
  - Professional Workflow
  - MVP Complete
impact_bullets:
  - MVP completed in December 2025 and prepared for beta rollout.
  - 14 of 18 milestones completed with architecture hardening in progress.
  - Citation-backed responses and validation improve professional trust and reviewability.
executive_summary:
  problem: Tax professionals need highly precise, source-grounded answers where factual errors and missing citations carry significant risk.
  solution: Built JTES as a production-oriented RAG platform with FastAPI + React, LlamaIndex orchestration, ChromaDB retrieval, modular embeddings (Ruri-v3/Sarashina/default), and strict citation validation.
  outcome: Delivered an MVP-complete, beta-ready foundation focused on precision, transparent sourcing, bilingual UX support, and operational controls for professional workflows.
use_case:
  summary: Professional Japanese tax workflows require fast, defensible answers backed by verifiable sources across law, guidance, and operational documentation.
  stakeholders:
    - Tax professionals and advisors
    - Compliance and review stakeholders
    - Product owners preparing beta validation
    - Business owners using tax interpretation support
architecture:
  overview: JTES uses a layered architecture with React frontend and FastAPI API over a RAG control plane, plus dedicated retrieval, LLM adapter, ingestion, and source-management subsystems.
  diagram:
    - "[React Frontend (:3000)] <-> [FastAPI API (:8001)]"
    - "                    |"
    - "             [RAG Control Plane]"
    - "          /          |           \\"
    - " [Retrieval]    [LLM Adapters]   [Validation]"
    - "      |                |               |"
    - "  [ChromaDB]   [OpenAI/Claude/Ollama]  [Citation checks]"
    - "                    |"
    - "      [Ingestion: PDF/XML/OCR/Chunking]"
    - "                    |"
    - "      [Source Watchers + Document Registry]"
tech_details:
  rag_prompt_patterns:
    - Citation-required response schema with source linkage and provenance cues.
    - Retrieval-first orchestration with context assembly before synthesis.
    - Validation pass for citation enforcement and hallucination-risk reduction.
    - Bilingual-ready prompting patterns for Japanese/English support.
  tools:
    - LlamaIndex for ingestion/indexing/retrieval orchestration
    - ChromaDB vector storage with configurable embedding providers
    - FastAPI backend and React + Vite + Material UI frontend
    - OCR and parsing stack (Tesseract OCR, pdfplumber, custom law XML parser)
    - LLM adapters for OpenAI, Claude, and Ollama with failover support
  constraints:
    - High-stakes tax domain requires conservative answer behavior and strict traceability.
    - Source freshness and jurisdiction nuance must be explicit for legal reliability.
    - OCR variability and document formatting differences affect ingestion quality.
    - Precision-focused retrieval and validation can increase response latency.
  tradeoffs:
    - Tighter citation and validation requirements improve trust but reduce response breadth.
    - Multi-provider flexibility increases resilience but adds configuration complexity.
    - Conservative refusal behavior lowers compliance risk but may frustrate exploratory users.
screenshots:
  - src: /assets/images/placeholder-architecture.svg
    alt: JTES RAG architecture diagram
    caption: System architecture spanning frontend, API, RAG control plane, and data layer.
  - src: /assets/images/placeholder-dashboard.svg
    alt: Citation-backed answer panel
    caption: Query and evidence experience with citations, provenance, and reviewer cues.
  - src: /assets/images/placeholder-workflow.svg
    alt: Expert review workflow for JTES
    caption: Ingestion-to-validation workflow including OCR quality gates and source controls.
lessons_learned:
  - Retrieval quality and chunk strategy drive downstream answer fidelity more than model choice alone.
  - Citation format consistency and provenance visibility improve reviewer speed and confidence.
  - Modular provider design helps operational resilience, but only with disciplined config management.
  - Domain SMEs are essential for credible offline evaluation in high-stakes workflows.
improve_next:
  - Expand benchmark coverage with adversarial tax and edge-case scenarios.
  - Strengthen source freshness controls and temporal validity handling.
  - Add per-answer evidence sufficiency scoring and confidence calibration.
  - Complete remaining milestones and structure beta feedback loops with professionals.
repro:
  runnable: false
  steps:
    - Start backend and frontend services (FastAPI on 8001, React on 3000) in the source project.
    - Ingest representative tax documents (PDF/XML/OCR paths) and verify registry/vector indexing.
    - Run representative professional queries and inspect citations, provenance, and validation outputs.
    - Review admin and metrics views for ingestion health, retrieval behavior, and provider configuration.
links:
  - label: JTES Project Link
    url: https://chatgpt.com/g/g-p-69506a2dfb04819193b3e819137d24b1-jtes/project
